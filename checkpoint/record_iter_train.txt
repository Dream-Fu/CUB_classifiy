train_Precision: 0.00000000, train_Loss: 5.29731464
train_Precision: 0.00000000, train_Loss: 5.29796505
train_Precision: 0.00000000, train_Loss: 5.29909086
train_Precision: 0.00000000, train_Loss: 5.29751110
train_Precision: 0.00000000, train_Loss: 5.29911423
train_Precision: 0.00000000, train_Loss: 5.29936123
train_Precision: 0.00000000, train_Loss: 5.29765463
train_Precision: 0.00000000, train_Loss: 5.29818058
train_Precision: 0.00000000, train_Loss: 5.29852200
train_Precision: 0.00000000, train_Loss: 5.29775047
train_Precision: 0.00000000, train_Loss: 5.29883289
train_Precision: 0.00000000, train_Loss: 5.29764080
train_Precision: 0.00000000, train_Loss: 5.29951000
train_Precision: 10.00000000, train_Loss: 5.29685926
train_Precision: 0.00000000, train_Loss: 5.29767227
train_Precision: 0.00000000, train_Loss: 5.29874134
train_Precision: 0.00000000, train_Loss: 5.29893398
train_Precision: 0.00000000, train_Loss: 5.29762650
train_Precision: 0.00000000, train_Loss: 5.29697657
train_Precision: 0.00000000, train_Loss: 5.29519844
train_Precision: 0.00000000, train_Loss: 5.30293846
train_Precision: 0.00000000, train_Loss: 5.29778719
train_Precision: 0.00000000, train_Loss: 5.29928493
train_Precision: 0.00000000, train_Loss: 5.30252743
train_Precision: 0.00000000, train_Loss: 5.29557514
train_Precision: 0.00000000, train_Loss: 5.29905748
train_Precision: 10.00000000, train_Loss: 5.29240084
train_Precision: 0.00000000, train_Loss: 5.30353546
train_Precision: 0.00000000, train_Loss: 5.29171991
train_Precision: 0.00000000, train_Loss: 5.29743099
train_Precision: 0.00000000, train_Loss: 5.30319738
train_Precision: 0.00000000, train_Loss: 5.30286217
train_Precision: 10.00000000, train_Loss: 5.29420185
train_Precision: 0.00000000, train_Loss: 5.30102158
train_Precision: 0.00000000, train_Loss: 5.30285883
train_Precision: 0.00000000, train_Loss: 5.29924870
train_Precision: 0.00000000, train_Loss: 5.29378176
train_Precision: 0.00000000, train_Loss: 5.30144358
train_Precision: 0.00000000, train_Loss: 5.30345392
train_Precision: 0.00000000, train_Loss: 5.30140829
train_Precision: 0.00000000, train_Loss: 5.30622768
train_Precision: 10.00000000, train_Loss: 5.29221106
train_Precision: 0.00000000, train_Loss: 5.30438662
train_Precision: 0.00000000, train_Loss: 5.29696751
train_Precision: 10.00000000, train_Loss: 5.29046488
train_Precision: 0.00000000, train_Loss: 5.29458046
train_Precision: 0.00000000, train_Loss: 5.30977392
train_Precision: 0.00000000, train_Loss: 5.29856586
train_Precision: 0.00000000, train_Loss: 5.29608727
train_Precision: 0.00000000, train_Loss: 5.29558992
train_Precision: 0.00000000, train_Loss: 5.29158068
train_Precision: 0.00000000, train_Loss: 5.29414225
train_Precision: 0.00000000, train_Loss: 5.29400730
train_Precision: 0.00000000, train_Loss: 5.28948450
train_Precision: 0.00000000, train_Loss: 5.30146551
train_Precision: 0.00000000, train_Loss: 5.29699326
train_Precision: 0.00000000, train_Loss: 5.29712200
train_Precision: 0.00000000, train_Loss: 5.30544662
train_Precision: 0.00000000, train_Loss: 5.29711819
train_Precision: 0.00000000, train_Loss: 5.30561161
train_Precision: 0.00000000, train_Loss: 5.30518866
train_Precision: 0.00000000, train_Loss: 5.30144882
train_Precision: 0.00000000, train_Loss: 5.30459118
train_Precision: 0.00000000, train_Loss: 5.30054140
train_Precision: 0.00000000, train_Loss: 5.29732609
train_Precision: 0.00000000, train_Loss: 5.30557346
train_Precision: 0.00000000, train_Loss: 5.29537344
train_Precision: 0.00000000, train_Loss: 5.29792738
train_Precision: 0.00000000, train_Loss: 5.29161882
train_Precision: 0.00000000, train_Loss: 5.29199266
train_Precision: 0.00000000, train_Loss: 5.29502869
train_Precision: 0.00000000, train_Loss: 5.29621792
train_Precision: 0.00000000, train_Loss: 5.30366945
train_Precision: 0.00000000, train_Loss: 5.30734348
train_Precision: 0.00000000, train_Loss: 5.29407978
train_Precision: 0.00000000, train_Loss: 5.29877996
train_Precision: 0.00000000, train_Loss: 5.29645634
train_Precision: 0.00000000, train_Loss: 5.30187511
train_Precision: 0.00000000, train_Loss: 5.29721975
train_Precision: 10.00000000, train_Loss: 5.28749371
train_Precision: 0.00000000, train_Loss: 5.29462910
train_Precision: 0.00000000, train_Loss: 5.30230093
train_Precision: 0.00000000, train_Loss: 5.28745365
train_Precision: 0.00000000, train_Loss: 5.28591824
train_Precision: 0.00000000, train_Loss: 5.29503965
train_Precision: 0.00000000, train_Loss: 5.28669643
train_Precision: 0.00000000, train_Loss: 5.29630470
train_Precision: 0.00000000, train_Loss: 5.30184650
train_Precision: 0.00000000, train_Loss: 5.30010509
train_Precision: 0.00000000, train_Loss: 5.29007530
train_Precision: 10.00000000, train_Loss: 5.30255985
train_Precision: 0.00000000, train_Loss: 5.29860783
train_Precision: 0.00000000, train_Loss: 5.29933214
train_Precision: 0.00000000, train_Loss: 5.30483723
train_Precision: 0.00000000, train_Loss: 5.29814243
train_Precision: 0.00000000, train_Loss: 5.29185820
train_Precision: 0.00000000, train_Loss: 5.30192423
train_Precision: 0.00000000, train_Loss: 5.29412556
train_Precision: 0.00000000, train_Loss: 5.29445171
train_Precision: 0.00000000, train_Loss: 5.29359150
train_Precision: 0.00000000, train_Loss: 5.30777788
train_Precision: 0.00000000, train_Loss: 5.29733086
train_Precision: 0.00000000, train_Loss: 5.29754972
train_Precision: 0.00000000, train_Loss: 5.29515457
train_Precision: 0.00000000, train_Loss: 5.30660200
train_Precision: 0.00000000, train_Loss: 5.28411770
train_Precision: 0.00000000, train_Loss: 5.30309963
train_Precision: 0.00000000, train_Loss: 5.29531050
train_Precision: 0.00000000, train_Loss: 5.29686594
train_Precision: 0.00000000, train_Loss: 5.29319906
train_Precision: 0.00000000, train_Loss: 5.29340887
train_Precision: 0.00000000, train_Loss: 5.30569315
train_Precision: 0.00000000, train_Loss: 5.28995657
train_Precision: 0.00000000, train_Loss: 5.29288292
train_Precision: 0.00000000, train_Loss: 5.29428577
train_Precision: 0.00000000, train_Loss: 5.29748154
train_Precision: 0.00000000, train_Loss: 5.28322697
train_Precision: 0.00000000, train_Loss: 5.29041052
train_Precision: 0.00000000, train_Loss: 5.30645943
train_Precision: 10.00000000, train_Loss: 5.29251337
train_Precision: 0.00000000, train_Loss: 5.30459023
train_Precision: 0.00000000, train_Loss: 5.29992771
train_Precision: 0.00000000, train_Loss: 5.30274677
train_Precision: 0.00000000, train_Loss: 5.29273224
train_Precision: 0.00000000, train_Loss: 5.28333092
train_Precision: 10.00000000, train_Loss: 5.28513622
train_Precision: 0.00000000, train_Loss: 5.29953814
train_Precision: 0.00000000, train_Loss: 5.30832529
train_Precision: 10.00000000, train_Loss: 5.27877283
train_Precision: 0.00000000, train_Loss: 5.30164671
train_Precision: 10.00000000, train_Loss: 5.29655886
train_Precision: 0.00000000, train_Loss: 5.29725552
train_Precision: 0.00000000, train_Loss: 5.28774118
train_Precision: 10.00000000, train_Loss: 5.29568148
train_Precision: 0.00000000, train_Loss: 5.30290985
train_Precision: 0.00000000, train_Loss: 5.30101299
train_Precision: 0.00000000, train_Loss: 5.29279470
train_Precision: 0.00000000, train_Loss: 5.28858852
train_Precision: 0.00000000, train_Loss: 5.29181528
